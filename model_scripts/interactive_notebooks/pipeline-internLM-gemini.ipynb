{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies \n",
    "import google.generativeai as genai\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from glob import glob\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key= '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "  \"temperature\": 0,\n",
    "  \"top_p\": 1,\n",
    "  \"top_k\": 1,\n",
    "  \"max_output_tokens\": 2048,\n",
    "}\n",
    "safety_settings = [\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "    \"threshold\": \"BLOCK_NONE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "    \"threshold\": \"BLOCK_NONE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "    \"threshold\": \"BLOCK_NONE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "    \"threshold\": \"BLOCK_NONE\"\n",
    "  }\n",
    "]\n",
    "model = genai.GenerativeModel('gemini-1.5-flash-latest', safety_settings=safety_settings, generation_config=generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate_content(\"hi\") #sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_type = \"simple\"\n",
    "question_type = \"complex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an expert in getting the answers from a given long answer with steps. These questions were asked about a chart.\n",
    "Task: Extract the final answer based on the given long sequence of reasoning with answer, given the question.\n",
    " \n",
    "Instructions:\n",
    "Append to your response and reasoning: 'The answer is: <final_answer>'. \n",
    "\n",
    "If a question asks about a column name, give the full and exact name for the column as it is written in answer. \n",
    "If a question required multiple outputs and the output contains multiple outputs as well, give it in the form: [<output1>, <output2> ..] where outputs are in sorted order. For example, if the output is 'Australia and India' give the answer as [Australia, India]. \n",
    "Ignore percentage signs.\n",
    "Remove the units from the answer. For example, if the answer is '10 million', give the answer as '10'. \n",
    "\n",
    "A few examples:\n",
    "\n",
    "Question: What is the value of the blue column?\n",
    "Given Answer: The blue column has the name 'XXX' and the value is 10.\n",
    "Your Answer: <reasoning>. The answer is: 10\n",
    "\n",
    "Question: What is the share of people above 65+ years in the small business category?\n",
    "Given Answer: To find the share of SME owners in small business over 65 years, we need to add the percentages for the '65-69 years' and '70-74 years' age groups. The calculation is as follows: 26.1% (65-69 years) + 11.8% (70-74 years) = 37.9%. So, the share of SME owners in small business over 65 years is 37.9%.\n",
    "Your Answer: <reasoning>. The answer is: 37.9\n",
    "\n",
    "Where <reasoning>. is your reasoning and your chain of thought to get to the answer.\n",
    "\n",
    "You need to carefully look at the question and the given answer. Think step by step.\n",
    "\n",
    "Question: {question}\n",
    "Given Answer: {answer}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import re\n",
    "  \n",
    "def modified_relaxed_accuracy(question:str,\n",
    "                        target: str,\n",
    "                        prediction: str,\n",
    "                        max_relative_change: float = 0.05) -> bool:\n",
    "  \"\"\"Calculates relaxed correctness.\n",
    "\n",
    "  The correctness tolerates certain error ratio defined by max_relative_change.\n",
    "  See https://arxiv.org/pdf/2203.10244.pdf, end of section 5.1:\n",
    "  “Following Methani et al. (2020), we use a relaxed accuracy measure for the\n",
    "  numeric answers to allow a minor inaccuracy that may result from the automatic\n",
    "  data extraction process. We consider an answer to be correct if it is within\n",
    "  5% of the gold answer. For non-numeric answers, we still need an exact match\n",
    "  to consider an answer to be correct. \n",
    "  This is now updated to take in account a lot more cases”\n",
    "\n",
    "  Args:\n",
    "    target: Target string.\n",
    "    prediction: Predicted string.\n",
    "    max_relative_change: Maximum relative change.\n",
    "\n",
    "  Returns:\n",
    "    Whether the prediction was correct given the specified tolerance.\n",
    "  \"\"\"\n",
    "  def _to_float(text: str) -> Optional[float]:\n",
    "    try:\n",
    "      if text.endswith(\"%\"):\n",
    "        return float(text.rstrip(\"%\")) / 100.0\n",
    "      else:\n",
    "        return float(text)\n",
    "    except ValueError:\n",
    "      return None\n",
    "    \n",
    "  def _remove_commas_from_numbers(text: str) -> str:\n",
    "    text = re.sub(r'(\\d*),(\\d+)', r'\\1\\2', text)\n",
    "    return text\n",
    "  \n",
    "  def _remove_spaces(text: str) -> str:\n",
    "    return text.replace(\" \", \"\")\n",
    "  \n",
    "  def _check_for_years(question: str) -> bool:\n",
    "    return \"year\" in question.lower()\n",
    "  \n",
    "  def _check_list(text: str) -> bool:\n",
    "    return text.startswith(\"[\") and text.endswith(\"]\")\n",
    "  \n",
    "  def _list_of_answers(target: str, prediction: str) -> bool:\n",
    "    target = target.split(\",\")\n",
    "    prediction = prediction.split(\",\")\n",
    "    target = sorted(target)\n",
    "    prediction = sorted(prediction)\n",
    "    return target == prediction\n",
    "  \n",
    "  prediction = _remove_commas_from_numbers(prediction)\n",
    "  target = _remove_commas_from_numbers(target)\n",
    "  \n",
    "  prediction_float = _to_float(prediction)\n",
    "  target_float = _to_float(target)\n",
    "  \n",
    "  if not _check_for_years(question) and (prediction_float is not None and target_float is not None):\n",
    "    try :\n",
    "      relative_change = abs(prediction_float - target_float) / abs(target_float)\n",
    "      return relative_change <= max_relative_change\n",
    "    except :\n",
    "      return False\n",
    "  else:\n",
    "    prediction = _remove_spaces(prediction)\n",
    "    target = _remove_spaces(target)\n",
    "    \n",
    "    if _check_list(target) and _check_list(prediction):\n",
    "      return _list_of_answers(target[1:-1], prediction[1:-1])\n",
    "    elif _check_list(target) or _check_list(prediction):\n",
    "        return _list_of_answers(target[1:-1], prediction) or _list_of_answers(target, prediction[1:-1])\n",
    "    else:\n",
    "      return target.lower() in prediction.lower() or (prediction.lower() in target.lower() and len(prediction) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(queries, max_workers=10):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        executor._max_workers = max_workers\n",
    "        results = list(executor.map(generate_content, queries))\n",
    "    return results\n",
    "\n",
    "def generate_content(query):\n",
    "    try:\n",
    "        resp = model.generate_content(query)\n",
    "        print(\".\", end=\"\")\n",
    "        return resp.text\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 'Error by gemini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_type = \"complex\"\n",
    "ques_type = \"complex\"\n",
    "\n",
    "categories = os.listdir('../Results/cog_agent/{chart_type}_{ques_type}/Initial_Run/')\n",
    "categories = [c.split('.')[0] for c in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    df = pd.read_json('../perturb_jsons/{}_{}/{}.json'.format(chart_type, ques_type, category))\n",
    "    questions = df['query'].tolist()\n",
    "    gold = df['label'].tolist()\n",
    "    pred = json.load(open(f'../Results/InternLM_XComposer2VL/{chart_type}_{ques_type}/Initial_Run/{category}.json','r'))\n",
    "    assert(len(pred) == len(questions))\n",
    "    queries = [prompt.format(question=question, answer=answer) for question, answer in zip(questions, pred)]\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        executor._max_workers = 16\n",
    "        model_responses = list(executor.map(generate_content, queries))\n",
    "    copy = model_responses.copy()\n",
    "    for i, resp in enumerate(copy):\n",
    "        resp = resp.strip()\n",
    "        if(resp[-1] == '.'):\n",
    "            resp = resp[:-1]\n",
    "        if 'The answer is: ' in resp:\n",
    "            x = resp.split('The answer is: ')\n",
    "            model_responses[i] = x[1]\n",
    "        elif 'the answer is: ' in resp:\n",
    "            x = resp.split('the answer is: ')\n",
    "            model_responses[i] = x[1]\n",
    "        elif 'The answer is ' in resp:\n",
    "            x = resp.split('The answer is ')\n",
    "            model_responses[i] = x[1]\n",
    "        else:\n",
    "            print(i, \"error by gemini\")\n",
    "\n",
    "    results = list(zip(questions, model_responses))\n",
    "    final_responses = []\n",
    "    for result in results:\n",
    "        question, response = result\n",
    "        final_responses.append(response.strip())\n",
    "        \n",
    "    final_responses = [response.split('=')[-1] for response in final_responses]\n",
    "    final_responses = [response.split('%')[0] for response in final_responses]\n",
    "\n",
    "    model_performance = []\n",
    "    results = list(zip(questions, model_responses))\n",
    "    for i, ans in enumerate(final_responses):\n",
    "        model_score = modified_relaxed_accuracy(questions[i],gold[i], ans)\n",
    "        model_performance.append(model_score)\n",
    "    \n",
    "    print(f\"For Category: {category}\")\n",
    "    print(\"Model performance: \", sum(model_performance),\"out of\", len(model_performance),\">>\", sum(model_performance)/len(model_performance))\n",
    "    print(\"-------------------------------------------------\")\n",
    "\n",
    "    json.dump()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chart-rob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
