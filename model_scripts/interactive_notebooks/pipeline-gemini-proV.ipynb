{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies \n",
    "import google.generativeai as genai\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from glob import glob\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key= '') #API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "  \"temperature\": 0,\n",
    "  \"top_p\": 1,\n",
    "  \"top_k\": 1,\n",
    "  \"max_output_tokens\": 2048,\n",
    "}\n",
    "safety_settings = [\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "    \"threshold\": \"BLOCK_NONE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "    \"threshold\": \"BLOCK_NONE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "    \"threshold\": \"BLOCK_NONE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "    \"threshold\": \"BLOCK_NONE\"\n",
    "  }\n",
    "]\n",
    "# or any model\n",
    "model = genai.GenerativeModel('gemini-1.5-flash-latest', safety_settings=safety_settings, generation_config=generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate_content(\"hi\") #sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_type = \"simple\"\n",
    "question_type = \"complex\"\n",
    "\n",
    "categories = os.listdir(\"../perturb_jsons/{}_{}\".format(chart_type, question_type))\n",
    "categories = [os.path.basename(category).split(\".\")[0] for category in categories]\n",
    "\n",
    "global_answers = {}\n",
    "category_wise_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" Task: You will be given a chart and a question. Answer the given question from the chart given to you.  \n",
    "Instructions: \n",
    "0) Look carefully at the chart, think about the type of chart, before answering the question directly.\n",
    "1) If a question asks about a column name, give the full and exact name for the column as it is written in the chart. \n",
    "2) If a question required multiple outputs, give it in the form: [<output1>, <output2> ..] where outputs are in sorted order. For example, if the output is 'Australia and India' give the answer as [Australia, India]. Please dont use this with column names invloving 'and' keyword. \n",
    "3) If a question requires doing arithmetic operations, calculate till the final number.\n",
    "4) If a question asks for what column a certain value is in, give the full and exact name of the column and not the value.\n",
    "5) If a question asks how many times a certain value appears, give the count and not the name of the columns where it appears.\n",
    "6) Answer without taking account of the units or scale given in chart. For example, if the chart has values in millions, you should ignore the scale and account absolute numbers. Remove the unit from your final answer and reason based on the absolute values obtained directly from the chart. Example: If your answer is 10 million USD, you should write 10 as your answer.\n",
    "7) It is known that the answer is obtainable from the chart given to you.\n",
    "8) Write your intermediate steps.\n",
    "\n",
    "The chart might not have exact values written on it, therefore you might need to find the exact value in that case with the help of the axes.\n",
    "Think step by step and append the answer at the last of your response in the form: \"... . The answer is: <answer>\"\n",
    "Question: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import re\n",
    "  \n",
    "def modified_relaxed_accuracy(question:str,\n",
    "                        target: str,\n",
    "                        prediction: str,\n",
    "                        max_relative_change: float = 0.05) -> bool:\n",
    "  \"\"\"Calculates relaxed correctness.\n",
    "\n",
    "  The correctness tolerates certain error ratio defined by max_relative_change.\n",
    "  See https://arxiv.org/pdf/2203.10244.pdf, end of section 5.1:\n",
    "  “Following Methani et al. (2020), we use a relaxed accuracy measure for the\n",
    "  numeric answers to allow a minor inaccuracy that may result from the automatic\n",
    "  data extraction process. We consider an answer to be correct if it is within\n",
    "  5% of the gold answer. For non-numeric answers, we still need an exact match\n",
    "  to consider an answer to be correct. \n",
    "  This is now updated to take in account a lot more cases”\n",
    "\n",
    "  Args:\n",
    "    target: Target string.\n",
    "    prediction: Predicted string.\n",
    "    max_relative_change: Maximum relative change.\n",
    "\n",
    "  Returns:\n",
    "    Whether the prediction was correct given the specified tolerance.\n",
    "  \"\"\"\n",
    "  def _to_float(text: str) -> Optional[float]:\n",
    "    try:\n",
    "      if text.endswith(\"%\"):\n",
    "        return float(text.rstrip(\"%\")) / 100.0\n",
    "      else:\n",
    "        return float(text)\n",
    "    except ValueError:\n",
    "      return None\n",
    "    \n",
    "  def _remove_commas_from_numbers(text: str) -> str:\n",
    "    text = re.sub(r'(\\d*),(\\d+)', r'\\1\\2', text)\n",
    "    return text\n",
    "  \n",
    "  def _remove_spaces(text: str) -> str:\n",
    "    return text.replace(\" \", \"\")\n",
    "  \n",
    "  def _check_for_years(question: str) -> bool:\n",
    "    return \"year\" in question.lower()\n",
    "  \n",
    "  def _check_list(text: str) -> bool:\n",
    "    return text.startswith(\"[\") and text.endswith(\"]\")\n",
    "  \n",
    "  def _list_of_answers(target: str, prediction: str) -> bool:\n",
    "    target = target.split(\",\")\n",
    "    prediction = prediction.split(\",\")\n",
    "    target = sorted(target)\n",
    "    prediction = sorted(prediction)\n",
    "    return target == prediction\n",
    "  \n",
    "  prediction = _remove_commas_from_numbers(prediction)\n",
    "  target = _remove_commas_from_numbers(target)\n",
    "  \n",
    "  prediction_float = _to_float(prediction)\n",
    "  target_float = _to_float(target)\n",
    "  \n",
    "  if not _check_for_years(question) and (prediction_float is not None and target_float is not None):\n",
    "    try :\n",
    "      relative_change = abs(prediction_float - target_float) / abs(target_float)\n",
    "      return relative_change <= max_relative_change\n",
    "    except :\n",
    "      return False\n",
    "  else:\n",
    "    prediction = _remove_spaces(prediction)\n",
    "    target = _remove_spaces(target)\n",
    "    \n",
    "    if _check_list(target) and _check_list(prediction):\n",
    "      return _list_of_answers(target[1:-1], prediction[1:-1])\n",
    "    elif _check_list(target) or _check_list(prediction):\n",
    "        return _list_of_answers(target[1:-1], prediction) or _list_of_answers(target, prediction[1:-1])\n",
    "    else:\n",
    "      return target.lower() in prediction.lower() or (prediction.lower() in target.lower() and len(prediction) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(queries, max_workers=10):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        executor._max_workers = max_workers\n",
    "        results = list(executor.map(generate_content, queries))\n",
    "    return results\n",
    "\n",
    "def generate_content(query):\n",
    "    try:\n",
    "        resp = model.generate_content(query)\n",
    "        print(\".\", end=\"\")\n",
    "        return resp.text\n",
    "    except Exception as e:\n",
    "        print(query, e)\n",
    "        return 'Error by gemini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    df = pd.read_json('../perturb_jsons/{}_{}/{}.json'.format(chart_type, question_type, category))\n",
    "    questions = df['query'].tolist()\n",
    "    gold_labels = df['label'].tolist()\n",
    "    imagenames = df['imgname'].tolist()\n",
    "    perturbations = df['perturbation'].tolist()\n",
    "    imagenames = [f\"../final_data/{chart_type}_{question_type}/plots/{perturbation}/{imagename}\" for perturbation, imagename in zip(perturbations, imagenames)]\n",
    "    images = [Image.open(img) for img in imagenames]\n",
    "\n",
    "    queries = []\n",
    "\n",
    "    for i, question in enumerate(questions):\n",
    "        text = prompt + question\n",
    "        queries.append([text, images[i]]) \n",
    "\n",
    "    model_responses = get_results(queries, max_workers= 16)\n",
    "    print(\"answers generated!\")\n",
    "    copy = model_responses.copy()\n",
    "    for i, resp in enumerate(copy):\n",
    "        if(resp[-1] == '.'):\n",
    "            resp = resp[:-1]\n",
    "        if 'The answer is: ' in resp:\n",
    "            x = resp.split('The answer is: ')\n",
    "            model_responses[i] = x[1]\n",
    "        elif 'the answer is: ' in resp:\n",
    "            x = resp.split('the answer is: ')\n",
    "            model_responses[i] = x[1]\n",
    "        elif 'The answer is ' in resp:\n",
    "            x = resp.split('The answer is ')\n",
    "            model_responses[i] = x[1]\n",
    "        else:\n",
    "            print(i, \"error by gemini\")\n",
    "\n",
    "    results = list(zip(questions, model_responses))\n",
    "    final_responses = []\n",
    "    for result in results:\n",
    "        question, response = result\n",
    "        final_responses.append(response.strip())\n",
    "        \n",
    "    final_responses = [response.split('=')[-1] for response in final_responses]\n",
    "    final_responses = [response.split('%')[0] for response in final_responses]\n",
    "\n",
    "    model_performance = []\n",
    "    results = list(zip(questions, model_responses))\n",
    "    for i, ans in enumerate(final_responses):\n",
    "        model_score = modified_relaxed_accuracy(questions[i],gold_labels[i], ans)\n",
    "        model_performance.append(model_score)\n",
    "\n",
    "    print('Category:', category)\n",
    "    print('Model accuracy:', sum(model_performance) / len(model_performance))\n",
    "    print()\n",
    "\n",
    "    del model_responses\n",
    "    del copy\n",
    "    del results\n",
    "    del final_responses\n",
    "    del model_performance\n",
    "    del df\n",
    "    del questions\n",
    "    del gold_labels\n",
    "    del imagenames\n",
    "    del perturbations\n",
    "    del images\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chart-rob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
